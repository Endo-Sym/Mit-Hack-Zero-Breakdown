from fastapi import FastAPI, HTTPException, UploadFile, File, Request, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, List, Optional
import hashlib
import hmac
import base64
import boto3
import json
import os
import pandas as pd
import numpy as np
from datetime import datetime
from io import StringIO
from dotenv import load_dotenv
from configs import SensorReadings, MachineData, ChatMessage
from retrivals import load_embeddings_from_file, search_query_in_embeddings
from BreakdownMaintenanceAdviceTool import BreakdownMaintenanceAdviceTool
from Orchestrator import Orchestrator
import uploads
from ml_predictor import get_predictor
from line_bot import get_line_notifier

# Load environment variables

from dotenv import load_dotenv

load_dotenv()
app = FastAPI(title="MITR Phol_Zero Breakdown Prediction API")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# AWS Bedrock client
bedrock_runtime = boto3.client(
    service_name='bedrock-runtime',
    region_name='us-west-2'
)

# Sensor threshold analysis
maintenance_tool = BreakdownMaintenanceAdviceTool()

# In-memory data storage (replace with database in production)
uploaded_data_store = {
    "dataframe": None,
    "machines": [],
    "metadata": {}
}

# LINE Bot users storage (replace with database in production)
line_users_store = {
    "users": [],  # List of LINE user IDs
    "alert_settings": {},  # User-specific alert settings
    "sent_alerts": {}  # Track sent alerts: {machine_id: {timestamp: alert_hash}}
}

def clean_sensor_data(df: pd.DataFrame) -> pd.DataFrame:
    """Clean and organize sensor data"""
    # Remove duplicates
    df = df.drop_duplicates()

    # Handle missing values
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())

    # Remove outliers using IQR method
    for col in numeric_columns:
        if col not in ['Machine_ID']:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 3 * IQR
            upper_bound = Q3 + 3 * IQR
            df[col] = df[col].clip(lower_bound, upper_bound)

    return df

def convert_sensor_names_to_tool_format(sensor_dict: dict) -> dict:
    """‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠ field ‡∏à‡∏≤‡∏Å frontend format ‡πÄ‡∏õ‡πá‡∏ô tool format"""
    mapping = {
        "PowerMotor": "Power_Motor",
        "CurrentMotor": "Current_Motor",
        "SpeedMotor": "Speed_Motor",
        "SpeedRoller": "Speed_Roller",
        "TempBrassBearingDE": "Temperator_Brass_bearing_DE",
        "TempBearingMotorNDE": "Temperator_Bearing_Motor_NDE",
        "TempOilGear": "Temperator_Oil_Gear",
        "TempWindingMotorPhase_U": "Temperator_Winding_Motor_Phase_U",
        "TempWindingMotorPhase_V": "Temperator_Winding_Motor_Phase_V",
        "TempWindingMotorPhase_W": "Temperator_Winding_Motor_Phase_W",
        "Vibration": "Vibration"
    }
    return {mapping.get(k, k): v for k, v in sensor_dict.items()}

# API Endpoints
@app.get("/")
def read_root():
    return {"message": "Zero Breakdown Prediction API", "status": "running"}

@app.post("/api/upload-csv")
async def upload_csv(file: UploadFile = File(...), custom_name: Optional[str] = None):
    """‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå CSV ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£"""
    try:
        # Read CSV file
        contents = await file.read()
        df = pd.read_csv(StringIO(contents.decode('utf-8')))

        # Validate required columns
        required_columns = [
            'Timestamp', 'Machine_ID', 'PowerMotor', 'CurrentMotor',
            'TempBrassBearingDE', 'SpeedMotor', 'TempOilGear',
            'TempBearingMotorNDE', 'TempWindingMotorPhase_U',
            'TempWindingMotorPhase_V', 'TempWindingMotorPhase_W', 'Vibration'
        ]

        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise HTTPException(
                status_code=400,
                detail=f"‡πÑ‡∏ü‡∏•‡πå CSV ‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {', '.join(missing_columns)}"
            )

        # Clean data
        original_rows = len(df)
        df = clean_sensor_data(df)

        # Convert Timestamp to datetime
        df['Timestamp'] = pd.to_datetime(df['Timestamp'])

        # Get machine list
        machines = sorted(df['Machine_ID'].unique().tolist())

        # Calculate data quality metrics
        missing_values = df.isnull().sum().sum()
        completeness = ((df.size - missing_values) / df.size) * 100

        # Get date range
        min_date = df['Timestamp'].min().strftime('%Y-%m-%d')
        max_date = df['Timestamp'].max().strftime('%Y-%m-%d')
        date_range = f"{min_date} ‡∏ñ‡∏∂‡∏á {max_date}"

        # Save as JSON file to disk - Local Path
        backend_dir = os.path.dirname(os.path.abspath(__file__))
        CSV_DIR = os.path.join(backend_dir, "csv_data")
        os.makedirs(CSV_DIR, exist_ok=True)

        if custom_name:
            json_filename = f"{custom_name}.json"
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            json_filename = f"factory_data_{timestamp}.json"

        json_filepath = os.path.join(CSV_DIR, json_filename)

        # Convert DataFrame to JSON with metadata
        json_data = {
            "metadata": {
                "filename": json_filename,
                "original_file": file.filename,
                "uploaded_at": datetime.now().isoformat(),
                "total_rows": len(df),
                "total_machines": len(machines),
                "date_range": date_range,
                "completeness": round(completeness, 2),
                "missing_values": int(missing_values),
                "custom_name": custom_name or f"factory_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            },
            "machines": machines,
            "data": json.loads(df.to_json(orient='records', date_format='iso'))
        }

        # Save to JSON file
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)

        # Store data globally
        uploaded_data_store["dataframe"] = df
        uploaded_data_store["machines"] = machines
        uploaded_data_store["metadata"] = {
            "total_rows": len(df),
            "total_machines": len(machines),
            "date_range": date_range,
            "completeness": round(completeness, 2),
            "missing_values": int(missing_values),
            "saved_file": json_filename,
            "filepath": json_filepath
        }

        return {
            "total_rows": len(df),
            "total_machines": len(machines),
            "machines": machines,
            "date_range": date_range,
            "saved_file": json_filename,
            "filepath": json_filepath,
            "data_quality": {
                "completeness": round(completeness, 2),
                "missing_values": int(missing_values)
            },
            "message": f"‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô JSON ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {json_filename}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/machines")
async def get_machines():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    try:
        if uploaded_data_store["dataframe"] is None:
            return {"machines": [], "message": "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV ‡∏Å‡πà‡∏≠‡∏ô"}

        return {
            "machines": uploaded_data_store["machines"],
            "metadata": uploaded_data_store["metadata"]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/machine-data/{machine_id}")
async def get_machine_data(machine_id: str, limit: int = 100):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£"""
    try:
        if uploaded_data_store["dataframe"] is None:
            raise HTTPException(status_code=404, detail="‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV ‡∏Å‡πà‡∏≠‡∏ô")

        df = uploaded_data_store["dataframe"]
        machine_df = df[df['Machine_ID'] == machine_id].sort_values('Timestamp', ascending=False).head(limit)

        if machine_df.empty:
            raise HTTPException(status_code=404, detail=f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ {machine_id}")

        # Get latest reading
        latest = machine_df.iloc[0]

        # Convert to sensor readings format
        sensor_data = {
            "PowerMotor": float(latest['PowerMotor']),
            "CurrentMotor": float(latest['CurrentMotor']),
            "TempBrassBearingDE": float(latest['TempBrassBearingDE']),
            "SpeedMotor": float(latest['SpeedMotor']),
            "SpeedRoller": float(latest.get('SpeedRoller', 5.5)),
            "TempOilGear": float(latest['TempOilGear']),
            "TempBearingMotorNDE": float(latest['TempBearingMotorNDE']),
            "TempWindingMotorPhase_U": float(latest['TempWindingMotorPhase_U']),
            "TempWindingMotorPhase_V": float(latest['TempWindingMotorPhase_V']),
            "TempWindingMotorPhase_W": float(latest['TempWindingMotorPhase_W']),
            "Vibration": float(latest['Vibration'])
        }

        # Analyze current status
        analysis = maintenance_tool.analyze_sensors(sensor_data)

        # Auto-send LINE alert if there are warnings (ONCE per problem)
        if analysis['alerts']:
            # Calculate risk score
            risk_score = len(analysis['alerts']) * 15
            risk_level = "‡∏ï‡πà‡∏≥" if risk_score < 30 else "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á" if risk_score < 60 else "‡∏™‡∏π‡∏á"

            # Create unique alert hash from alerts
            alert_hash = hashlib.md5(
                "|".join(sorted(analysis['alerts'])).encode('utf-8')
            ).hexdigest()

            # Check if we already sent this exact alert
            last_sent = line_users_store["sent_alerts"].get(machine_id, {})
            if last_sent.get("alert_hash") == alert_hash:
                print(f"‚è≠Ô∏è  Skip duplicate alert for {machine_id} (already sent)")
            else:
                # Send LINE alert with repair instructions
                try:
                    line_notifier = get_line_notifier()
                    if line_notifier.is_configured() and line_users_store["users"]:
                        # Get detailed repair manual from RAG
                        repair_advice = "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£"
                        try:
                            backend_dir = os.path.dirname(os.path.abspath(__file__))
                            embeddings_file_path = os.path.join(backend_dir, "embeddings.json")
                            manuls_file_path = os.path.join(backend_dir, "manuls.txt")

                            embeddings = load_embeddings_from_file(embeddings_file_path)

                            with open(manuls_file_path, "r", encoding="utf-8") as file:
                                text_fitz = file.read()  # ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå

                            # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                            texts_strip = text_fitz.split("\n")  # ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏û‡∏≤‡∏£‡∏≤‡∏Å‡∏£‡∏≤‡∏ü‡πÑ‡∏î‡πâ

                            # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å
                            texts = [text for text in texts_strip if text.strip()]

                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö query_text ‡∏à‡∏≤‡∏Å request ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                            query_text = "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö: " + ", ".join(analysis['alerts'])

                            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô embeddings
                            results = search_query_in_embeddings(query_text, embeddings, texts)

                            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏∞‡∏ö‡∏ö Feed Mill

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query_text}
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å: {results}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á:
‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°
‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á
‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì"""

                            # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• qwen.qwen3-32b-v1:0 ‡∏ú‡πà‡∏≤‡∏ô API
                            response_body = bedrock_runtime.converse(
                                modelId="qwen.qwen3-32b-v1:0",
                                messages=[
                                    {
                                        "role": "user",
                                        "content": [{"text": prompt}]
                                    }
                                ],
                                inferenceConfig={
                                    "maxTokens": 1024
                                }
                            )
                            repair_advice = response_body['output']['message']['content'][0]['text']
                        except Exception as e:
                            print(f"‚ö†Ô∏è RAG failed: {str(e)}")

                        messages = line_notifier.create_flex_alert_message(
                            machine_id=machine_id,
                            alerts=analysis['alerts'],
                            risk_score=risk_score,
                            risk_level=risk_level,
                            sensor_readings=sensor_data,
                            repair_advice=repair_advice
                        )

                        # Send to all users with alerts enabled
                        for user_id in line_users_store["users"]:
                            if line_users_store["alert_settings"].get(user_id, True):
                                line_notifier.send_push_message(user_id, messages)
                                print(f"üì§ Auto-alert sent to LINE user: {user_id} for {machine_id}")

                        # Mark as sent
                        line_users_store["sent_alerts"][machine_id] = {
                            "alert_hash": alert_hash,
                            "timestamp": latest['Timestamp'].isoformat()
                        }
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to send auto LINE alert: {str(e)}")

        return {
            "machine_id": machine_id,
            "timestamp": latest['Timestamp'].isoformat(),
            "sensor_readings": sensor_data,
            "alerts": analysis['alerts'],
            "status_summary": analysis['status_summary'],
            "historical_count": len(machine_df)
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/analyze-sensors")
async def analyze_sensors(data: MachineData):
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• sensor ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"""
    try:
        sensor_dict = data.sensor_readings.model_dump()
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠ field ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö tool format
        sensor_dict_for_tool = convert_sensor_names_to_tool_format(sensor_dict)
        analysis = maintenance_tool.analyze_sensors(sensor_dict_for_tool)

        # Generate maintenance advice using AWS Bedrock with RAG
        if analysis['alerts']:
            try:
                # Get the backend directory path
                backend_dir = os.path.dirname(os.path.abspath(__file__))
                embeddings_file_path = os.path.join(backend_dir, "embeddings.json")
                manuls_file_path = os.path.join(backend_dir, "manuls.txt")

                embeddings = load_embeddings_from_file(embeddings_file_path)

                with open(manuls_file_path, "r", encoding="utf-8") as file:
                    text_fitz = file.read()  # ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå

                # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                texts_strip = text_fitz.split("\n")  # ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏û‡∏≤‡∏£‡∏≤‡∏Å‡∏£‡∏≤‡∏ü‡πÑ‡∏î‡πâ

                # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å
                texts = [text for text in texts_strip if text.strip()]

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö query_text ‡∏à‡∏≤‡∏Å request ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                query_text = f"‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ {data.machine_type}: " + ", ".join(analysis['alerts'])

                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô embeddings
                results = search_query_in_embeddings(query_text, embeddings, texts)

                prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏∞‡∏ö‡∏ö Feed Mill

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query_text}
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å: {results}

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sensor:
{json.dumps(sensor_dict, indent=2, ensure_ascii=False)}

‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö:
{chr(10).join(analysis['alerts'])}

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ sensor:
- ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á PowerMotor ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 290-315 kW
- ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á CurrentMotor ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 280‚Äì320 Amp
- ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á TempBrassBearingDE ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á < 75¬∞C
- ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á SpeedMotor ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 1480‚Äì1495 rpm
- ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á TempOilGear ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á < 65¬∞C
- ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á TempBearingMotorNDE ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á < 85¬∞C
- ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á TempWindingMotorPhase_U/V/W ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á < 105¬∞C

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á:
‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°
‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á
‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì"""

                # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• qwen.qwen3-32b-v1:0 ‡∏ú‡πà‡∏≤‡∏ô API
                response_body = bedrock_runtime.converse(
                    modelId="qwen.qwen3-32b-v1:0",
                    messages=[
                        {
                            "role": "user",
                            "content": [{"text": prompt}]
                        }
                    ],
                    inferenceConfig={
                        "maxTokens": 1024
                    }
                )
                maintenance_advice = response_body['output']['message']['content'][0]['text']

            except Exception as e:
                print(f"‚ö†Ô∏è RAG lookup failed: {str(e)}")
                maintenance_advice = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠: {str(e)}"

        else:
            maintenance_advice = "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥"

        return {
            "timestamp": data.timestamp,
            "machine_type": data.machine_type,
            "sensor_readings": sensor_dict,
            "alerts": analysis['alerts'],
            "status_summary": analysis['status_summary'],
            "recommended_action": maintenance_advice
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/predict-breakdown")
async def predict_breakdown(data: MachineData):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£"""
    try:
        sensor_dict = data.sensor_readings.model_dump()
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠ field ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö tool format
        sensor_dict_for_tool = convert_sensor_names_to_tool_format(sensor_dict)
        analysis = maintenance_tool.analyze_sensors(sensor_dict_for_tool)

        # Calculate risk score
        risk_score = len(analysis['alerts']) * 10
        risk_level = "‡∏ï‡πà‡∏≥" if risk_score < 30 else "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á" if risk_score < 60 else "‡∏™‡∏π‡∏á"

        prompt = f"""‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ {data.machine_type}:

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sensor:
{json.dumps(sensor_dict, indent=2, ensure_ascii=False)}

‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö:
{chr(10).join(analysis['alerts']) if analysis['alerts'] else '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤'}

‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á: {risk_score}/100
‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á: {risk_level}

‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ ABB M3BP355SMB4

‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö:
1. ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡∏à‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢
2. ‡∏≠‡∏≤‡∏¢‡∏∏‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏¢‡∏π‡πà
3. ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î"""
        
        
        # response = bedrock_runtime.invoke_model(
        #     modelId='us.anthropic.claude-3-haiku-20240307-v1:0',
        #     body=json.dumps({
        #         "anthropic_version": "bedrock-2023-05-31",
        #         "max_tokens": 1024,
        #         "messages": [
        #             {
        #                 "role": "user",
        #                 "content": prompt
        #             }
        #         ]
        #     })
        # )

        # response_body = json.loads(response['body'].read())
        # prediction = response_body['content'][0]['text']
        # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• qwen.qwen3-32b-v1:0 ‡∏ú‡πà‡∏≤‡∏ô API
        response = bedrock_runtime.converse(
            modelId="qwen.qwen3-32b-v1:0",
            messages=[
                {
                    "role": "user",
                    "content": [{"text": prompt}]
                }
            ],
            inferenceConfig={
                "maxTokens": 1024
            }
        )
        prediction = response['output']['message']['content'][0]['text']

        return {
            "machine_type": data.machine_type,
            "risk_score": risk_score,
            "risk_level": risk_level,
            "prediction": prediction,
            "alerts": analysis['alerts']
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/predict-ml-breakdown")
async def predict_ml_breakdown(data: MachineData):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ ML Model (pm_model_fullpipeline.py)"""
    try:
        sensor_dict = data.sensor_readings.model_dump()

        # Get ML predictor
        predictor = get_predictor()

        # Make prediction
        ml_result = predictor.predict_single(sensor_dict)

        # Add metadata
        ml_result["machine_type"] = data.machine_type
        ml_result["timestamp"] = data.timestamp

        return ml_result

    except Exception as e:
        import traceback
        print(f"Error in /api/predict-ml-breakdown: {str(e)}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/repair-manual")
async def get_repair_manual(request: ChatMessage):

    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏° (‡πÉ‡∏ä‡πâ AI ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°)"""
    try:
        # Get the backend directory path
        backend_dir = os.path.dirname(os.path.abspath(__file__))
        embeddings_file_path = os.path.join(backend_dir, "embeddings.json")
        manuls_file_path = os.path.join(backend_dir, "manuls.txt")

        embeddings = load_embeddings_from_file(embeddings_file_path)

        with open(manuls_file_path, "r", encoding="utf-8") as file:
            text_fitz = file.read()  # ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå

        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        texts_strip = text_fitz.split("\n")  # ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏û‡∏≤‡∏£‡∏≤‡∏Å‡∏£‡∏≤‡∏ü‡πÑ‡∏î‡πâ

        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å
        texts = [text for text in texts_strip if text.strip()]

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö query_text ‡∏à‡∏≤‡∏Å request ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        query_text = request.message  # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ message ‡∏à‡∏≤‡∏Å request ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤

        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô embeddings
        results = search_query_in_embeddings(query_text, embeddings, texts)

        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏∞‡∏ö‡∏ö Feed Mill

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query_text}
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å: {results}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á:
‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°
‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á
‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì"""

        # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• qwen.qwen3-32b-v1:0 ‡∏ú‡πà‡∏≤‡∏ô API
        response_body = bedrock_runtime.converse(
            modelId="qwen.qwen3-32b-v1:0",
            messages=[
                {
                    "role": "user",
                    "content": [{"text": prompt}]
                }
            ],
            inferenceConfig={
                "maxTokens": 1024
            }
        )
        manual_content = response_body['output']['message']['content'][0]['text']

        return {
            "question": request.message,
            "answer": manual_content
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
@app.post("/api/chat")
async def chat_agent(request: ChatMessage):
    """Agentic AI Chat - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
    try:
        print(f"Received chat request: {request.message}")
        # Determine which function to use based on message
        messager = request.message
        Host_Agent = Orchestrator(messager)
        agent_response=Host_Agent.run(messager) 

        return {
            "message": request.message,
            "response": agent_response
        }
    except Exception as e:
        import traceback
        print(f"Error in /api/chat: {str(e)}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/orchestrator-chat")
async def orchestrator_chat(request: ChatMessage):
    """Orchestrator-based Chat - ‡πÉ‡∏ä‡πâ Tool calling ‡∏ú‡πà‡∏≤‡∏ô AWS Bedrock"""
    try:
        print(f"Received orchestrator chat request: {request.message}")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Orchestrator instance ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á user input ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ
        orchestrator = Orchestrator()

        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ run() ‡πÇ‡∏î‡∏¢‡∏™‡πà‡∏á user_input ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ (‡πÉ‡∏ä‡πâ _get_user_input ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô)
        response_text = orchestrator.run(user_input=request.message)

        return {
            "message": request.message,
            "response": response_text,
            "tools_used": [],  # Orchestrator ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ tools ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô
            "stop_reason": "completed"
        }

    except Exception as e:
        import traceback
        print(f"Error in /api/orchestrator-chat: {str(e)}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

# ===== Embeddings Management Endpoints =====

class RenameRequest(BaseModel):
    old_filename: str
    new_name: str

@app.post("/api/upload-pdf")
async def upload_pdf(file: UploadFile = File(...), custom_name: Optional[str] = None):
    """‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings"""
    try:
        # Save temp PDF file
        import tempfile
        temp_dir = tempfile.gettempdir()
        temp_path = os.path.join(temp_dir, file.filename)

        with open(temp_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # Generate and save embeddings
        result = uploads.save_embedding(temp_path, custom_name)

        # Remove temp file
        os.remove(temp_path)

        return {
            "success": True,
            "message": "‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à",
            **result
        }
    except Exception as e:
        import traceback
        print(f"Error in /api/upload-pdf: {str(e)}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/embeddings")
async def list_embeddings():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå embeddings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    try:
        files = uploads.list_embedding_files()
        return {
            "files": files,
            "total": len(files)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/embeddings/{filename}")
async def get_embedding_info(filename: str):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå embedding"""
    try:
        info = uploads.get_embedding_file_info(filename)
        return info
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/embeddings/rename")
async def rename_embedding(request: RenameRequest):
    """‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå embedding"""
    try:
        result = uploads.rename_embedding_file(request.old_filename, request.new_name)
        return {
            "success": True,
            "message": "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à",
            **result
        }
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except FileExistsError as e:
        raise HTTPException(status_code=409, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/embeddings/{filename}")
async def delete_embedding(filename: str):
    """‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå embedding"""
    try:
        result = uploads.delete_embedding_file(filename)
        return {
            "success": True,
            "message": "‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à",
            **result
        }
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ===== LINE Bot Endpoints =====

def verify_line_signature(body: bytes, signature: str) -> bool:
    """Verify LINE webhook signature"""
    line_notifier = get_line_notifier()
    if not line_notifier.channel_secret:
        return False

    hash_digest = hmac.new(
        line_notifier.channel_secret.encode('utf-8'),
        body,
        hashlib.sha256
    ).digest()

    computed_signature = base64.b64encode(hash_digest).decode('utf-8')
    return hmac.compare_digest(signature, computed_signature)


@app.post("/api/line/webhook")
async def line_webhook(request: Request, x_line_signature: str = Header(None)):
    """LINE Bot Webhook endpoint"""
    try:
        body = await request.body()
        print(f"üì• Received webhook request")
        print(f"   Body length: {len(body)}")
        print(f"   Signature: {x_line_signature}")

        # Verify signature (disabled for testing)
        # if not verify_line_signature(body, x_line_signature or ""):
        #     raise HTTPException(status_code=400, detail="Invalid signature")

        # Parse JSON
        try:
            events_data = json.loads(body.decode('utf-8'))
            print(f"   Parsed JSON: {events_data}")
        except json.JSONDecodeError as je:
            print(f"‚ö†Ô∏è JSON decode error: {str(je)}")
            # Return OK for verification requests that might not have valid JSON
            return {"status": "ok"}

        # Handle events
        events_list = events_data.get('events', [])
        print(f"   Events count: {len(events_list)}")

        for event in events_list:
            print(f"   Event type: {event.get('type')}")

            if event['type'] == 'message' and event['message']['type'] == 'text':
                # Handle text message
                user_id = event['source']['userId']
                message_text = event['message']['text'].lower()

                # Add user to storage if not exists
                if user_id not in line_users_store["users"]:
                    line_users_store["users"].append(user_id)
                    print(f"‚úÖ New LINE user registered: {user_id}")

                # Reply based on message
                line_notifier = get_line_notifier()

                if '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞' in message_text or 'status' in message_text:
                    # Send current machine status
                    if uploaded_data_store["dataframe"] is not None:
                        machines = uploaded_data_store["machines"]
                        reply = f"üìä ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£\n\n"
                        reply += f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á: {len(machines)} ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á\n"
                        reply += f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£: {', '.join(machines[:5])}"
                        if len(machines) > 5:
                            reply += f" ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏≠‡∏µ‡∏Å {len(machines) - 5} ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á"
                    else:
                        reply = "‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£"

                    line_notifier.send_push_message(user_id, [{"type": "text", "text": reply}])

                elif '‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠' in message_text or 'help' in message_text:
                    help_text = """ü§ñ ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ:

1Ô∏è‚É£ '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞' - ‡∏î‡∏π‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£
2Ô∏è‚É£ '‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô ‡πÄ‡∏õ‡∏¥‡∏î' - ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
3Ô∏è‚É£ '‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô ‡∏õ‡∏¥‡∏î' - ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
4Ô∏è‚É£ '‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠' - ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á

‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á"""

                    line_notifier.send_push_message(user_id, [{"type": "text", "text": help_text}])

                elif '‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô' in message_text:
                    if '‡πÄ‡∏õ‡∏¥‡∏î' in message_text:
                        line_users_store["alert_settings"][user_id] = True
                        reply = "‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á"
                    elif '‡∏õ‡∏¥‡∏î' in message_text:
                        line_users_store["alert_settings"][user_id] = False
                        reply = "‚ùå ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß"
                    else:
                        status = "‡πÄ‡∏õ‡∏¥‡∏î ‚úÖ" if line_users_store["alert_settings"].get(user_id, True) else "‡∏õ‡∏¥‡∏î ‚ùå"
                        reply = f"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: {status}"

                    line_notifier.send_push_message(user_id, [{"type": "text", "text": reply}])

                else:
                    # Default welcome message
                    welcome_text = """‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! üëã

‡∏ú‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏≠‡∏ó‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ Zero Breakdown

‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""

                    line_notifier.send_push_message(user_id, [{"type": "text", "text": welcome_text}])

            elif event['type'] == 'follow':
                # User added bot as friend
                user_id = event['source']['userId']
                if user_id not in line_users_store["users"]:
                    line_users_store["users"].append(user_id)
                    line_users_store["alert_settings"][user_id] = True
                    print(f"‚úÖ New LINE friend: {user_id}")

        print("‚úÖ Webhook processed successfully")
        return {"status": "ok"}

    except Exception as e:
        import traceback
        print(f"‚ùå Error in LINE webhook: {str(e)}")
        print(traceback.format_exc())
        # Return 200 OK even on error to prevent LINE from retrying
        return {"status": "error", "message": str(e)}


@app.post("/api/line/send-alert")
async def send_line_alert(machine_id: str, alerts: List[str], risk_score: int = 0,
                         risk_level: str = "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö", user_id: Optional[str] = None):
    """‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ú‡πà‡∏≤‡∏ô LINE Bot"""
    try:
        line_notifier = get_line_notifier()

        if not line_notifier.is_configured():
            raise HTTPException(status_code=503, detail="LINE Bot not configured")

        # Create flex message
        messages = line_notifier.create_flex_alert_message(
            machine_id=machine_id,
            alerts=alerts,
            risk_score=risk_score,
            risk_level=risk_level
        )

        sent_count = 0

        if user_id:
            # Send to specific user
            if line_notifier.send_push_message(user_id, messages):
                sent_count = 1
        else:
            # Send to all users with alerts enabled
            for uid in line_users_store["users"]:
                if line_users_store["alert_settings"].get(uid, True):
                    if line_notifier.send_push_message(uid, messages):
                        sent_count += 1

        return {
            "success": True,
            "sent_to": sent_count,
            "message": f"‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á {sent_count} ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ"
        }

    except Exception as e:
        import traceback
        print(f"Error sending LINE alert: {str(e)}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/line/users")
async def get_line_users():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ LINE Bot"""
    try:
        users_with_settings = []
        for user_id in line_users_store["users"]:
            users_with_settings.append({
                "user_id": user_id,
                "alerts_enabled": line_users_store["alert_settings"].get(user_id, True)
            })

        return {
            "total_users": len(line_users_store["users"]),
            "users": users_with_settings
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/line/test-alert")
async def test_line_alert():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ú‡πà‡∏≤‡∏ô LINE"""
    try:
        test_alerts = [
            "CurrentMotor ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: 350 A (‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥)",
            "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥: 92¬∞C"
        ]

        result = await send_line_alert(
            machine_id="Feed Mill 1 (‡∏ó‡∏î‡∏™‡∏≠‡∏ö)",
            alerts=test_alerts,
            risk_score=65,
            risk_level="‡∏™‡∏π‡∏á"
        )

        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)